from typing import List, Dict, Optional, Tuple


class CerebrasProvider:
    id = "cerebras"
    name = "Cerebras"
    description = "Cerebras Inference (OpenAI-compatible) language models"
    supported = True

    async def chat(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float = 1,
        max_tokens: Optional[int] = None,
    ) -> Tuple[str, str]:
        from .cerebras_client import cerebras_client
        return await cerebras_client.chat(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )

    async def stream_chat(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float = 1,
        max_tokens: Optional[int] = None,
    ):
        from .cerebras_client import cerebras_client
        async for chunk in cerebras_client.stream_chat(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        ):
            yield chunk

    async def list_models(self) -> List[Dict[str, object]]:
        from .cerebras_client import cerebras_client
        model_ids = cerebras_client.list_models()

        models: List[Dict[str, object]] = []
        for model_id in model_ids:
            name_parts = model_id.replace("/", " ").replace("-", " ").title().split()
            name = " ".join(name_parts)
            models.append(
                {
                    "id": model_id,
                    "name": name,
                    "provider": "cerebras",
                    "description": f"{name}",
                }
            )
        return models


provider = CerebrasProvider()
